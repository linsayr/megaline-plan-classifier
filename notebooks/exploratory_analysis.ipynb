{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34463de9",
   "metadata": {},
   "source": [
    "# Plan Recommendation Model (Smart or Ultra)\n",
    "\n",
    "Megaline, a telecommunications company, aims to modernize the assignment of mobile plans for its customers. Currently, a significant portion of its users still use legacy plans, which limits operational efficiency and company profitability. To address this challenge, it has been proposed to develop a machine learning model capable of analyzing the monthly behavior of users—in terms of calls, text messages, and mobile data usage—and accurately recommend one of the two new available plans: Smart or Ultra.\n",
    "\n",
    "This project implements a supervised classification approach using historical data from customers who have already migrated to one of the new plans. The main objective is to build a predictive model with at least 75% accuracy that automates plan recommendation and improves customer experience. To achieve this, a structured methodology will be followed, including:\n",
    "\n",
    "- Initial data exploration: The file users_behavior.csv will be analyzed to understand its structure and quality, ensuring there are no null values or anomalies that could affect the model.\n",
    "- Data preparation: Independent variables (such as calls, minutes, messages, and data usage) and the target variable (is_ultra) will be identified. Then, data will be split into three sets: training (60%), validation (20%), and testing (20%).\n",
    "- Model training: Different classification algorithms will be trained and compared, including decision trees, random forests, and logistic regression, tuning their hyperparameters to optimize performance.\n",
    "- Performance evaluation: The accuracy metric will be used to measure each model's quality on the validation set. The best performing model will be selected for the final test.\n",
    "- Final validation: The final model will be evaluated on the test set to measure its generalization ability on new data.\n",
    "- Sanity check: It will be verified that the model performs significantly better than a trivial prediction strategy, such as always choosing the majority class.\n",
    "\n",
    "With this approach, Megaline seeks a practical and effective solution that contributes to improving business decision-making and optimizing the customer experience through the use of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b28f2",
   "metadata": {},
   "source": [
    "## 1.1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01f30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6fc00",
   "metadata": {},
   "source": [
    "## 1.2 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c4146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and split it into features and target\n",
    "df = pd.read_csv('../data/users_behavior.csv')\n",
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e84d6d",
   "metadata": {},
   "source": [
    "## 1.3 Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ff1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training+validation and test sets (80% train+val, 20% test)\n",
    "features_temp, features_test, target_temp, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345)\n",
    "\n",
    "# Then split training+validation into training and validation sets (75% train, 25% val of 80%)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.25, random_state=12345)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48354581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1928\n",
      "Validation set size: 643\n",
      "Test set size: 643\n",
      "First rows of the dataset:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive statistics:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {features_train.shape[0]}\")\n",
    "print(f\"Validation set size: {features_valid.shape[0]}\")\n",
    "print(f\"Test set size: {features_test.shape[0]}\")\n",
    "\n",
    "# Show first rows of the dataset\n",
    "print(\"First rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Show general info about the dataset\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556cb0c2",
   "metadata": {},
   "source": [
    "## 2. Split Source Data into Three Sets (Training, Validation, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9663657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Split 80% train+validation and 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the 80% into 60% training and 20% validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f24bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1928\n",
      "Validation set size: 643\n",
      "Test set size: 643\n"
     ]
    }
   ],
   "source": [
    "# Show sizes of subsets\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_valid.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396ba33",
   "metadata": {},
   "source": [
    "Analysis: The dataset was successfully split into three subsets:\n",
    "\n",
    "Training set: 1,928 records (~60%)\n",
    "\n",
    "Validation set: 643 records (~20%)\n",
    "\n",
    "Test set: 643 records (~20%)\n",
    "\n",
    "This division allows training models on a representative sample (60%), tuning hyperparameters and evaluating performance with a validation set (20%), and finally assessing generalization with an independent test set (20%). This strategy helps prevent overfitting and ensures reliable model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296de656",
   "metadata": {},
   "source": [
    "## 3. Investigate the quality of different models by tuning hyperparameters\n",
    "\n",
    "This step consists of:\n",
    "- Training different classification models.\n",
    "- Adjusting their hyperparameters.\n",
    "- Evaluating performance on the validation set.\n",
    "- Choosing the best model. Using these 3 models: Decision Tree, Random Forest, and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9768105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different hyperparameters\n",
    "\n",
    "# Decision Tree with varying depths\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    acc = accuracy_score(target_valid, predictions)\n",
    "    print(f\"Decision Tree (max_depth={depth}) - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Random Forest with different numbers of trees\n",
    "for est in range(10, 101, 10):\n",
    "    model = RandomForestClassifier(n_estimators=est, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    acc = accuracy_score(target_valid, predictions)\n",
    "    print(f\"Random Forest (n_estimators={est}) - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_valid)\n",
    "acc = accuracy_score(target_valid, predictions)\n",
    "print(f\"Logistic Regression - Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f63c7",
   "metadata": {},
   "source": [
    "Conclusion: The Random Forest model proved to be the most effective during testing. Specifically, with 80 trees (n_estimators=80), it achieved the highest accuracy of 0.7994 on the validation set. Therefore, this model will be selected for the final evaluation on the test set to confirm its overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17988ccc",
   "metadata": {},
   "source": [
    "## 4. Verify model quality using the test set\n",
    "\n",
    "To verify the quality of the selected model, Random Forest with n_estimators=80, the test set features and targets will be used (features_test and target_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71282192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the full training set\n",
    "final_model = RandomForestClassifier(n_estimators=80, random_state=12345)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = final_model.predict(features_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "\n",
    "print(f\"Model accuracy on test set: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25caeae6",
   "metadata": {},
   "source": [
    "Conclusion: The final model, a Random Forest with 80 trees, achieved an accuracy of 78.69% on the test set, surpassing the minimum required threshold of 75%. This indicates the model can reliably predict whether a customer should switch to the Smart or Ultra plan based on their past behavior. Therefore, it is suitable for production deployment and to assist Megaline’s commercial team in plan recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7729993",
   "metadata": {},
   "source": [
    "## 5. Sanity check on the model\n",
    "\n",
    "A sanity check verifies the model is not learning by chance or making meaningless predictions. It helps confirm that there is a real relationship between data and predictions.\n",
    "\n",
    "Strategy: Train with randomized target. We train the same model (Random Forest), but with the target variable shuffled randomly. If accuracy remains high, that is a warning sign. If accuracy drops close to 0.5 (random chance), then the original model truly learned meaningful patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle target values\n",
    "shuffled_target = target.sample(frac=1, random_state=12345).reset_index(drop=True)\n",
    "\n",
    "# Train model with shuffled target\n",
    "model_sanity = RandomForestClassifier(n_estimators=80, random_state=12345)\n",
    "model_sanity.fit(features_train, shuffled_target[:len(features_train)])  # keep correct length\n",
    "\n",
    "# Evaluate on the real validation set\n",
    "predictions_sanity = model_sanity.predict(features_valid)\n",
    "accuracy_sanity = accuracy_score(target_valid, predictions_sanity)\n",
    "\n",
    "print(f\"Accuracy of model with shuffled target: {accuracy_sanity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d1676c",
   "metadata": {},
   "source": [
    "Conclusion: The sanity check showed that the model trained with randomized labels achieved an accuracy of 0.6703, significantly lower than the real model (0.7869). This confirms the original model learned real data patterns, not just noise or coincidences. However, the random model’s performance was not completely low, suggesting some detectable patterns may exist even without correct labels. This invites a deeper review of features to ensure no data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85685e0e",
   "metadata": {},
   "source": [
    "## 5.1 Check feature importance (feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f886f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get importance of each feature\n",
    "importances = final_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': features.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display most important features\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac58be9",
   "metadata": {},
   "source": [
    "Conclusion: The most relevant feature for predicting the plan type is mobile data usage (mb_used), followed by call duration (minutes) and number of calls and messages. This indicates mobile data consumption behavior is strongly related to plan choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01febe8b",
   "metadata": {},
   "source": [
    "## 5.2 Cross-validation with cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "final_model = RandomForestClassifier(n_estimators=80, random_state=12345)\n",
    "\n",
    "# Calculate cross-validation scores (default scoring='accuracy')\n",
    "cv_scores = cross_val_score(final_model, features_train, target_train, cv=5)\n",
    "\n",
    "# Show results\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01f532",
   "metadata": {},
   "source": [
    "Conclusion: The RandomForestClassifier model achieved a mean accuracy of 80.34% with a 5-fold cross-validation and a standard deviation of 1.22%. This indicates the model generalizes well and performs robustly. Also, mobile data usage remains the most influential feature for predicting the plan type, providing a useful basis for Megaline’s business decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8860f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c168a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5e113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
